# Claude OaK Agents

**Self-Improving Agent System for Claude Code**

A comprehensive agent ecosystem with **29+ specialized agents** that **learns from experience**, **fills capability gaps automatically**, and **optimizes itself with 80-95% automation**.

Built on [claude-squad](https://github.com/jamsajones/claude-squad) with **OaK Architecture** (Options and Knowledge) for data-driven continuous improvement.

**NEW**: Now with **Anthropic Agent Skills parity** - multi-file packages, bundled executable scripts, dynamic discovery, and MCP integration!

---

## üéØ What Makes This Different?

| Feature | Basic Agents | Anthropic Skills | Claude OaK Agents |
|---------|--------------|------------------|-------------------|
| Specialized agents | ‚úÖ Static | ‚úÖ Skills | ‚úÖ 29+ agents (grows automatically) |
| Multi-file packages | ‚ùå No | ‚úÖ Yes | ‚úÖ Yes (NEW) |
| Bundled scripts | ‚ùå No | ‚úÖ Yes | ‚úÖ Yes (NEW) |
| Dynamic discovery | ‚ùå No | ‚úÖ Yes | ‚úÖ Yes (NEW) |
| MCP integration | ‚ùå No | ‚úÖ Yes | ‚úÖ Yes (NEW) |
| Performance tracking | ‚ùå None | ‚ùå None | ‚úÖ Comprehensive telemetry |
| Learning from experience | ‚ùå Static | ‚ùå Static | ‚úÖ Continuous improvement |
| Capability gap detection | ‚ùå Manual | ‚ùå Manual | ‚úÖ Automatic creation |
| Agent optimization | ‚ùå Manual | ‚ùå Manual | ‚úÖ A/B testing + ML |
| Portfolio management | ‚ùå None | ‚ùå None | ‚úÖ Strategic HR (agent-auditor) |
| Maintenance | ‚ùå Manual | ‚ùå Manual | ‚úÖ 15 min/week automated |

**TL;DR**: All the power of Anthropic's Agent Skills PLUS self-learning, telemetry, and autonomous optimization!

---

## üöÄ Quick Install (5 Minutes)

### Prerequisites

- **Claude Code** installed and working
- **macOS** (automation scripts use macOS features)
- **Python 3.8+** (usually pre-installed on macOS)
- **Git** for cloning repository

### Installation

```bash
# 1. Clone to your Projects directory
git clone https://github.com/robertmnyborg/claude-oak-agents.git ~/Projects/claude-oak-agents
cd ~/Projects/claude-oak-agents

# 2. Install agents (creates symlinks - won't overwrite existing)
mkdir -p ~/.claude/agents
ln -s ~/Projects/claude-oak-agents/agents/* ~/.claude/agents/

# 3. Install telemetry hooks (automatic performance logging)
./hooks/install_hooks.sh
# Sets up automatic logging of all agent invocations
# Adds environment variables to ~/.zshrc

# 4. Install automation (optional but recommended)
./automation/install_automation.sh
# Adds shell prompts and scheduled reviews

# 5. Restart terminal or reload shell
source ~/.zshrc

# 6. You're done! Start using agents normally in Claude Code
```

**That's it!** The system is now:
- ‚úÖ Logging every agent invocation automatically (via hooks)
- ‚úÖ Tracking performance metrics (duration, success, quality)
- ‚úÖ Detecting capability gaps (auto-creates missing agents)
- ‚úÖ Prompting you when reviews are due (shell integration)
- ‚úÖ Learning from experience (continuous improvement)

---

## üí° How It Works

### For You (Simple)

```
1. Use Claude Code normally ‚Üí Agents handle tasks
2. System learns automatically ‚Üí Telemetry captures performance
3. Get prompts when reviews are due ‚Üí "15 new invocations, 5 min review"
4. Review insights ‚Üí See what's working, what's not
5. System improves automatically ‚Üí Agents get better over time
```

### Under the Hood (Smart)

```
Your Request
    ‚Üì
Agent Delegation (with gap detection)
    ‚Üì
Telemetry Capture (automatic)
    ‚Üì
Performance Analysis (scheduled: weekly/monthly)
    ‚Üì
Gap Detection & Agent Creation (automatic with your approval)
    ‚Üì
A/B Testing & Improvement (Phase 5)
    ‚Üì
ML-Driven Optimization (Phase 6)
    ‚Üì
Improved Delegation (smarter over time)
```

---

## ü§ñ 29+ Specialized Agents

### Core Development (7 agents)
- **frontend-developer** - React/Vue/Angular, UI/UX, browser compatibility
- **backend-architect** - APIs, databases, microservices, system design
- **infrastructure-specialist** - AWS CDK, Terraform, cloud deployment
- **mobile-developer** - React Native, iOS, Android
- **blockchain-developer** - Solidity, Web3, DeFi protocols
- **ml-engineer** - TensorFlow/PyTorch, ML pipelines, MLOps
- **legacy-maintainer** - Java, C#, enterprise systems

### Quality & Security (5 agents)
- **security-auditor** - Penetration testing, compliance, threat modeling
- **code-reviewer** - Quality gates, standards enforcement
- **unit-test-expert** - Comprehensive testing, edge cases
- **dependency-scanner** - Supply chain security, vulnerabilities
- **qa-specialist** - Integration testing, E2E validation

### Infrastructure & Operations (4 agents)
- **systems-architect** - High-level design, technical specs
- **performance-optimizer** - Bottleneck identification, optimization
- **debug-specialist** - Critical error resolution (HIGHEST PRIORITY)
- **git-workflow-manager** - Git operations, PRs, branch management

### Analysis & Planning (5 agents)
- **state-analyzer** - State feature extraction and ranking
- **business-analyst** - Requirements analysis, stakeholder communication
- **data-scientist** - Data analysis, statistical processing
- **project-manager** - Multi-step coordination, timeline management
- **agent-auditor** - **NEW**: Strategic HR for agent portfolio

### Documentation & Content (3 agents)
- **technical-documentation-writer** - API docs, technical specifications
- **content-writer** - Marketing content, user-facing docs
- **changelog-recorder** - Automatic changelog generation

### Special Purpose (3+ agents)
- **design-simplicity-advisor** - KISS enforcement (mandatory)
- **agent-creator** - Meta-agent for creating new specialists
- **general-purpose** - Fallback for basic tasks

**Plus**: System automatically creates new agents when gaps are detected!

---

## üìä Key Features

### 1. **Multi-File Agent Packages** (NEW) ‚úÖ
Agents can now be sophisticated packages with bundled scripts and documentation:
- **Bundled Scripts**: Pre-tested Python/Bash scripts for 10-100x faster execution
- **Reference Documentation**: OWASP guides, compliance checklists, methodology docs
- **Code Templates**: Reusable templates for security tests, configurations, etc.
- **Backward Compatible**: Single-file agents still fully supported

**Example**: security-auditor bundles CVE scanner, secrets detector, and threat modeler scripts.

### 2. **Dynamic Agent Discovery** (NEW) ‚úÖ
Lightweight metadata-only system prompt for 93% smaller context:
- **Metadata-First**: Load only triggers/keywords at startup (6KB vs 87KB)
- **On-Demand Loading**: Full definitions loaded when agent is invoked
- **Smart Matching**: Keyword, file pattern, and domain-based discovery
- **Scalable**: Support 100+ agents without prompt bloat

**Status**: Built and ready, opt-in via `./scripts/enable_metadata_prompts.sh`
**Result**: 90% smaller prompts, 4x faster classification, lower token costs.

### 3. **Model Context Protocol (MCP)** (NEW) ‚úÖ
Standardized telemetry and agent coordination via Anthropic's MCP:
- **oak-telemetry server**: Standardized telemetry access and logging
- **oak-agents server**: Agent discovery, metadata, script execution
- **Industry Standard**: Better ecosystem integration
- **Replaces Hooks**: Cleaner, more maintainable than custom scripts

**See**: [mcp/README.md](mcp/README.md) for setup.

### 4. **Automatic Telemetry** (Phase 1-3) ‚úÖ
Every agent invocation is logged automatically with:
- Agent used and task type
- Duration and outcome
- Quality ratings
- State features (languages, frameworks, etc.)

**Zero effort required** - happens in background via hooks or MCP.

### 5. **Capability Gap Detection** (Phase 1-3) ‚úÖ
When you need an agent that doesn't exist:
```
You: "Analyze the ROI of this investment"
System: No financial-analyst exists
System: Creates financial-analyst automatically
System: Notifies you to review before deployment
You: Approve specification
System: Agent deployed and ready to use!
```

**Adapts to YOUR needs** - not just predefined agents.

### 6. **Agent-Auditor (Agentic HR)** (Phase 5) ‚úÖ
Strategic portfolio manager that:
- Evaluates all agent performance monthly
- Identifies capability gaps from patterns
- Detects redundancy and overlap
- Recommends creation/refactoring/consolidation/deprecation

**Like having HR for your agents** - maintains portfolio health.

### 7. **Intelligent Prompting** (Phase 1-5) ‚úÖ
System prompts you when action needed:
- **Weekly**: "15 new invocations - 5 min review due"
- **Monthly**: "Agent audit complete - 30 min curation"
- **Agent Reviews**: "2 new agents awaiting approval"

**Shell prompts on terminal open** + **macOS notifications** + **daily checks**.

### 8. **Human-in-the-Loop Quality Control** (Phase 5) ‚úÖ
New agents require your review before first deployment:
```bash
oak-list-pending-agents    # See what's pending
oak-review-agent <name>    # Read specification
oak-approve-agent <name>   # Deploy immediately
oak-modify-agent <name>    # Edit before approving
```

**After first approval**, system can auto-update based on learning.

### 9. **A/B Testing & Continuous Improvement** (Phase 5) ‚úÖ
Improved agent versions tested scientifically:
- Original vs improved comparison
- Statistical significance testing
- Performance metrics tracked
- Best version deployed automatically

**Evidence-based evolution** - not guesswork.

### 10. **ML Pipeline (Coming Soon)** (Phase 6) üöß
Machine learning will:
- Learn optimal agent selection patterns
- Predict agent performance before delegation
- Recommend best agents for each task type
- Continuously improve recommendations

**The longer you use it, the smarter it gets.**

### 11. **Model Tier Optimization** (NEW) ‚úÖ
Strategic model selection for cost and performance optimization:
- **Premium tier (Opus)**: Strategic planning, architecture (6 agents)
- **Balanced tier (Sonnet)**: Standard development work (19 agents)
- **Fast tier (Haiku)**: Execution tasks, procedures (8 agents)

**Impact**:
- 21% cost reduction vs single-model approach
- 3-10x faster execution for procedural tasks
- Better strategic decisions from premium models
- Optimal quality-cost balance for each agent type

**See**: [Model Selection Strategy](docs/MODEL_SELECTION_STRATEGY.md) for complete details.

---

## üéÆ Daily Usage

### Using Agents (Exactly Like Before)

```
# In Claude Code, just ask normally:
You: "Implement OAuth2 authentication"
You: "Fix this deployment error"
You: "Create a financial dashboard"

# System handles everything automatically:
# - Classifies request
# - Selects best agent(s)
# - Logs telemetry
# - Detects gaps if needed
# - Creates new agents when helpful
```

### Weekly Rhythm (15 Minutes)

**Monday 9am**: Weekly review runs automatically ‚Üí Notification sent

**You run:**
```bash
oak-weekly-review
```

**You see**:
- Performance summary (5 min read)
- Top performing agents
- Areas for improvement
- New invocations summary

**System tracks** you reviewed ‚Üí Stops nagging until next week.

### Monthly Rhythm (1 Hour)

**1st of month 10am**: Monthly analysis runs ‚Üí Curation agenda ready

**You run:**
```bash
oak-monthly-review
```

**You see**:
- Agent portfolio audit report
- Capability gaps detected
- Recommended new agents
- Refactoring suggestions
- Redundancy analysis

**You review** recommendations (~30 min) ‚Üí Approve actions ‚Üí System executes.

### Agent Review (As Needed)

When system creates a new agent:

**You get notified**: "New agent ready for review"

**You run:**
```bash
oak-list-pending-agents    # See pending
oak-review-agent financial-analyst  # Read spec
oak-approve-agent financial-analyst  # Deploy
```

**Takes 5-10 minutes** per agent. First-time only; future updates are automatic.

---

## üìÅ Project Structure

```
claude-oak-agents/
‚îú‚îÄ‚îÄ agents/                         # All agent definitions
‚îÇ   ‚îú‚îÄ‚îÄ pending_review/             # New agents awaiting approval
‚îÇ   ‚îú‚îÄ‚îÄ rejected/                   # Rejected agents archive
‚îÇ   ‚îú‚îÄ‚îÄ frontend-developer.md       # Core 29 agents
‚îÇ   ‚îú‚îÄ‚îÄ agent-auditor.md            # NEW: Strategic HR
‚îÇ   ‚îú‚îÄ‚îÄ security-auditor-multifile/ # Example multi-file agent package
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ telemetry/                      # Performance data (local only)
‚îÇ   ‚îú‚îÄ‚îÄ agent_invocations.jsonl     # All invocations logged
‚îÇ   ‚îú‚îÄ‚îÄ success_metrics.jsonl       # Quality ratings
‚îÇ   ‚îú‚îÄ‚îÄ routing_failures.jsonl      # Capability gaps detected
‚îÇ   ‚îî‚îÄ‚îÄ agent_reviews.jsonl         # Review decisions
‚îú‚îÄ‚îÄ automation/                     # Automation system
‚îÇ   ‚îú‚îÄ‚îÄ install_automation.sh       # One-command setup
‚îÇ   ‚îú‚îÄ‚îÄ oak_prompts.sh              # Shell integration
‚îÇ   ‚îú‚îÄ‚îÄ oak_notify.sh               # Notification system
‚îÇ   ‚îî‚îÄ‚îÄ launchd/                    # Scheduled tasks
‚îú‚îÄ‚îÄ scripts/                        # Analysis & review scripts
‚îÇ   ‚îú‚îÄ‚îÄ automation/                 # Weekly/monthly analysis
‚îÇ   ‚îú‚îÄ‚îÄ phase4/                     # Dashboards & feedback
‚îÇ   ‚îú‚îÄ‚îÄ phase5/                     # Agent audit & A/B testing
‚îÇ   ‚îú‚îÄ‚îÄ phase6/                     # ML pipeline (future)
‚îÇ   ‚îú‚îÄ‚îÄ shared/                     # NEW: Shared utilities (KISS approach)
‚îÇ   ‚îú‚îÄ‚îÄ measure_token_costs.py      # NEW: Token cost analysis
‚îÇ   ‚îú‚îÄ‚îÄ enable_metadata_prompts.sh  # NEW: Enable metadata-only prompts
‚îÇ   ‚îî‚îÄ‚îÄ agent_review.py             # Review workflow
‚îú‚îÄ‚îÄ core/                           # Core infrastructure
‚îÇ   ‚îú‚îÄ‚îÄ agent_loader.py             # Agent loading with progressive disclosure
‚îÇ   ‚îî‚îÄ‚îÄ generate_agent_metadata.py  # Metadata generation for discovery
‚îú‚îÄ‚îÄ hooks/                          # Automatic telemetry hooks
‚îÇ   ‚îú‚îÄ‚îÄ pre_agent_hook.py           # Logs before agent runs
‚îÇ   ‚îî‚îÄ‚îÄ post_agent_hook.py          # Logs after completion
‚îú‚îÄ‚îÄ docs/oak-design/                # Architecture docs
‚îÇ   ‚îú‚îÄ‚îÄ OAK_ARCHITECTURE.md         # Complete design
‚îÇ   ‚îú‚îÄ‚îÄ IMPLEMENTATION_GUIDE.md     # Technical details
‚îÇ   ‚îî‚îÄ‚îÄ 6_MONTH_DEPLOYMENT_PLAN.md  # Rollout roadmap
‚îú‚îÄ‚îÄ configs/                        # Configuration files
‚îÇ   ‚îú‚îÄ‚îÄ curation_config.yaml        # Agent curation settings
‚îÇ   ‚îú‚îÄ‚îÄ rl_config.yaml              # ML pipeline config
‚îÇ   ‚îî‚îÄ‚îÄ ab_test_template.yaml       # A/B test template
‚îú‚îÄ‚îÄ reports/                        # Generated reports
‚îú‚îÄ‚îÄ CLAUDE.md                       # Agent delegation rules
‚îú‚îÄ‚îÄ QUICK_START.md                  # 5-minute guide
‚îî‚îÄ‚îÄ README.md                       # This file
```

---

## üîß Available Commands

### Daily Use

```bash
oak-status              # System status and pending items
oak-check-pending       # Quick check for pending agents
```

### Weekly/Monthly

```bash
oak-weekly-review       # Run weekly analysis (15 min)
oak-monthly-review      # Run monthly curation (1 hr)
oak-health-check        # System health validation
oak-dashboard           # Performance dashboard
```

### Agent Review

```bash
oak-list-pending-agents         # List agents awaiting approval
oak-review-agent <name>         # Review agent specification
oak-approve-agent <name>        # Approve and deploy
oak-modify-agent <name>         # Edit before approving
oak-reject-agent <name> "..."   # Reject with reason
```

### Optimization & Measurement

```bash
# Measure token costs before optimizing
python3 scripts/measure_token_costs.py              # Analyze last 30 days
python3 scripts/measure_token_costs.py --period=7   # Last 7 days
python3 scripts/measure_token_costs.py --show-agents # Cost breakdown by agent

# Enable metadata-only prompts (93% smaller prompts)
./scripts/enable_metadata_prompts.sh                # One-command enablement

# Learn more about optimizations
cat docs/ENABLE_METADATA_PROMPTS.md                # Metadata-only prompts guide
cat scripts/shared/README.md                        # Shared utilities guide
```

---

## üìà The Learning Flywheel

```
Use Agents
    ‚Üì
Telemetry Captures Performance
    ‚Üì
Weekly/Monthly Analysis
    ‚Üì
Insights & Recommendations
    ‚Üì
A/B Testing (Phase 5)
    ‚Üì
Improvements Deployed
    ‚Üì
ML Learning (Phase 6)
    ‚Üì
Better Agent Selection
    ‚Üì
(Back to Use Agents - but smarter)
```

**Each iteration makes the system better at serving YOUR needs.**

---

## üóìÔ∏è Deployment Timeline

| Phase | Status | Timeline | What You Get |
|-------|--------|----------|--------------|
| **1-3** | ‚úÖ Complete | Day 1 | Telemetry, hooks, gap detection, agent-auditor |
| **4** | ‚úÖ Complete | Month 1-2 | Dashboards, feedback collection, transition models |
| **5** | ‚úÖ Complete | Month 3-4 | A/B testing, curation automation, review workflow |
| **6** | üöß In Progress | Month 5-6 | ML pipeline, policy learning, autonomous optimization |

**You get value immediately** and it compounds over time.

---

## ‚öôÔ∏è Configuration

### Environment Variables (Optional)

Add to `~/.zshrc`:
```bash
export OAK_TELEMETRY_ENABLED=true
export OAK_TELEMETRY_DIR="$HOME/Projects/claude-oak-agents/telemetry"
export OAK_PROMPT_FEEDBACK=false  # Enable interactive feedback prompts
export PYTHONPATH="$HOME/Projects/claude-oak-agents:$PYTHONPATH"
```

Reload:
```bash
source ~/.zshrc
```

### Disabling Features

**Disable telemetry** (not recommended):
```bash
export OAK_TELEMETRY_ENABLED=false
```

**Uninstall automation**:
```bash
./automation/uninstall_automation.sh
```

**Remove agents**:
```bash
rm ~/.claude/agents/*
```

---

## üõ†Ô∏è Troubleshooting

### Hooks Not Working

**Check installation:**
```bash
ls -la ~/.claude/hooks/
# Should show: pre_agent.sh, post_agent.sh
```

**Fix permissions:**
```bash
chmod +x hooks/*.py
```

**Test telemetry:**
```bash
python3 scripts/test_telemetry_e2e.py
```

### Shell Prompts Not Showing

**Check ~/.zshrc:**
```bash
grep "oak_prompts.sh" ~/.zshrc
```

**If missing, add:**
```bash
echo 'source "$HOME/Projects/claude-oak-agents/automation/oak_prompts.sh"' >> ~/.zshrc
source ~/.zshrc
```

### Scheduled Tasks Not Running

**Check launchd jobs:**
```bash
launchctl list | grep com.oak
```

**Reload if needed:**
```bash
launchctl load ~/Library/LaunchAgents/com.oak.weekly-review.plist
```

### More Help

- **[QUICK_START.md](QUICK_START.md)** - 5-minute setup guide
- **[automation/README.md](automation/README.md)** - Automation system details
- **[hooks/README.md](hooks/README.md)** - Telemetry hooks guide
- **GitHub Issues** - Report problems or ask questions

---

## üéØ Next Steps

1. ‚úÖ **Install** (5 minutes) - Follow Quick Install above
2. ‚úÖ **Use normally** - Start using agents in Claude Code
3. ‚úÖ **First week** - Let telemetry collect data
4. ‚úÖ **Week 2** - First weekly review (oak-weekly-review)
5. ‚úÖ **Month 1** - First monthly audit (oak-monthly-review)
6. ‚úÖ **Month 2** - First capability gap filled automatically
7. ‚úÖ **Month 3** - First A/B test running
8. ‚úÖ **Month 6** - ML pipeline active, full autonomous optimization

**The sooner you start, the sooner the learning begins.**

---

## üìö Documentation

### Getting Started
- **[QUICK_START.md](QUICK_START.md)** - 5-minute getting started
- **[EXECUTIVE_OVERVIEW.md](docs/archive/EXECUTIVE_OVERVIEW.md)** - Comparison vs claude-squad (archived)

### NEW: Anthropic Skills Parity
- **[docs/MULTI_FILE_AGENTS.md](docs/MULTI_FILE_AGENTS.md)** - Multi-file packages, bundled scripts, MCP
- **[docs/MIGRATION_GUIDE.md](docs/MIGRATION_GUIDE.md)** - Migrate single-file ‚Üí multi-file
- **[docs/METADATA_ONLY_PROMPTS.md](docs/METADATA_ONLY_PROMPTS.md)** - Metadata-only system prompts (90% smaller)
- **[docs/ENABLE_METADATA_PROMPTS.md](docs/ENABLE_METADATA_PROMPTS.md)** - Enable metadata-only (opt-in)
- **[mcp/README.md](mcp/README.md)** - Model Context Protocol setup

### Architecture & Design
- **[docs/oak-design/OAK_ARCHITECTURE.md](docs/oak-design/OAK_ARCHITECTURE.md)** - Complete architecture
- **[docs/oak-design/6_MONTH_DEPLOYMENT_PLAN.md](docs/oak-design/6_MONTH_DEPLOYMENT_PLAN.md)** - Detailed roadmap

### Automation & Telemetry
- **[automation/README.md](automation/README.md)** - Automation system
- **[hooks/README.md](hooks/README.md)** - Telemetry hooks
- **[agents/pending_review/README.md](agents/pending_review/README.md)** - Review workflow

---

## ü§ù Contributing

Contributions welcome! Priority areas:

- **Phase 6 ML Pipeline**: Offline RL implementation
- **Agent Improvements**: Based on telemetry analysis
- **Dashboard UI**: Web interface for analytics
- **Integration**: Additional tool integrations
- **Documentation**: Examples, tutorials, use cases

See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

---

## üôè Credits

- **Original System**: [claude-squad](https://github.com/jamsajones/claude-squad) by jamsajones
- **OaK Architecture**: Inspired by hierarchical RL research
- **Contributors**: See [CONTRIBUTORS.md](CONTRIBUTORS.md)

---

## üìù License

MIT License - See [LICENSE](LICENSE) for details

---

## üîó Links

- **Original Repo**: https://github.com/jamsajones/claude-squad
- **Documentation**: [docs/oak-design/](docs/oak-design/)
- **Issues**: [GitHub Issues](https://github.com/robertmnyborg/claude-oak-agents/issues)

---

**Status**: ‚úÖ Phases 1-5 Complete | üöß Phase 6 In Progress | 29+ Agents | Self-Learning Active | Automation Ready

**Get Started**: [Quick Install](#-quick-install-5-minutes) ‚¨ÜÔ∏è
